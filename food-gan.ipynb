{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nfrom tqdm import tqdm\nimport torch.nn as nn\nimport imageio as iio\nimport matplotlib.pyplot as plt\nfrom torch.autograd import Variable\nfrom torch.optim import lr_scheduler\nfrom torchvision.datasets import Food101 as Food\nfrom torchvision.utils import save_image\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2023-07-08T11:56:20.641436Z","iopub.status.idle":"2023-07-08T11:56:20.642008Z","shell.execute_reply.started":"2023-07-08T11:56:20.641823Z","shell.execute_reply":"2023-07-08T11:56:20.641843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the parameters for the training process\nn_epochs = 100\nbatch_size = 128\nlr = 0.0002\nb1 = 0.5\nb2 = 0.999\nlatent_dim = 100\nmean = 0.5\nstd = 0.5","metadata":{"execution":{"iopub.status.busy":"2023-07-08T11:56:20.642949Z","iopub.status.idle":"2023-07-08T11:56:20.643496Z","shell.execute_reply.started":"2023-07-08T11:56:20.643290Z","shell.execute_reply":"2023-07-08T11:56:20.643309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir \"food_train\"\n!mkdir 'food_test'","metadata":{"execution":{"iopub.status.busy":"2023-07-07T20:25:13.828060Z","iopub.execute_input":"2023-07-07T20:25:13.828525Z","iopub.status.idle":"2023-07-07T20:25:16.031490Z","shell.execute_reply.started":"2023-07-07T20:25:13.828482Z","shell.execute_reply":"2023-07-07T20:25:16.029968Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Data preprocessing","metadata":{}},{"cell_type":"code","source":"trans = transforms.Compose([transforms.ToTensor(), \n                            transforms.Normalize([mean], [std])\n                           ])\ndataset_train = Food(root=\"./food_train\", download = True, transform = trans)\ndataset_test = Food(root=\"./food_test\", download = True, transform = trans, split = \"test\")","metadata":{"execution":{"iopub.status.busy":"2023-07-07T20:25:31.719327Z","iopub.execute_input":"2023-07-07T20:25:31.719801Z","iopub.status.idle":"2023-07-07T20:38:57.197229Z","shell.execute_reply.started":"2023-07-07T20:25:31.719750Z","shell.execute_reply":"2023-07-07T20:38:57.196126Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Downloading https://data.vision.ee.ethz.ch/cvl/food-101.tar.gz to ./food_train/food-101.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4996278331/4996278331 [05:02<00:00, 16498638.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./food_train/food-101.tar.gz to ./food_train\nDownloading https://data.vision.ee.ethz.ch/cvl/food-101.tar.gz to ./food_test/food-101.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4996278331/4996278331 [05:25<00:00, 15354290.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./food_test/food-101.tar.gz to ./food_test\n","output_type":"stream"}]},{"cell_type":"code","source":"print('No. of train images:', len(dataset_train))\nprint('No. of test images:', len(dataset_test))","metadata":{"execution":{"iopub.status.busy":"2023-07-07T20:39:48.385812Z","iopub.execute_input":"2023-07-07T20:39:48.386676Z","iopub.status.idle":"2023-07-07T20:39:48.393986Z","shell.execute_reply.started":"2023-07-07T20:39:48.386628Z","shell.execute_reply":"2023-07-07T20:39:48.392955Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"No. of train images: 75750\nNo. of test images: 25250\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = dataset_train + dataset_test\ndataset","metadata":{"execution":{"iopub.status.busy":"2023-07-08T11:56:20.639176Z","iopub.status.idle":"2023-07-08T11:56:20.640039Z","shell.execute_reply.started":"2023-07-08T11:56:20.639763Z","shell.execute_reply":"2023-07-08T11:56:20.639789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dataloader = DataLoader(dataset, batch_size= batch_size, shuffle= False)\n\n# batch1 = iter(dataloader)\n# for i in batch1:\n#     print(batch1[i])\n#     break\n# # print(batch1)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-07T21:01:51.409939Z","iopub.execute_input":"2023-07-07T21:01:51.410450Z","iopub.status.idle":"2023-07-07T21:01:52.740394Z","shell.execute_reply.started":"2023-07-07T21:01:51.410409Z","shell.execute_reply":"2023-07-07T21:01:52.738712Z"},"trusted":true},"execution_count":41,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[41], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m batch_size, shuffle\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m batch1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(dataloader)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m batch1:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(batch1[i])\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:264\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    204\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [3, 512, 512] at entry 0 and [3, 384, 512] at entry 3"],"ename":"RuntimeError","evalue":"stack expects each tensor to be equal size, but got [3, 512, 512] at entry 0 and [3, 384, 512] at entry 3","output_type":"error"}]},{"cell_type":"code","source":"# img_shape = dataset[0].shape\n# channels, img_sizex, img_sizey = img_shape\n# print(img_shape)\n# print(channels)","metadata":{"execution":{"iopub.status.busy":"2023-07-07T20:56:40.407354Z","iopub.execute_input":"2023-07-07T20:56:40.407792Z","iopub.status.idle":"2023-07-07T20:56:40.461427Z","shell.execute_reply.started":"2023-07-07T20:56:40.407762Z","shell.execute_reply":"2023-07-07T20:56:40.459694Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":28,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m img_shape \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[1;32m      2\u001b[0m channels, img_sizex, img_sizey \u001b[38;5;241m=\u001b[39m img_shape\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(img_shape)\n","\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"],"ename":"AttributeError","evalue":"'tuple' object has no attribute 'shape'","output_type":"error"}]},{"cell_type":"code","source":"# plt.figure(figsize=(12,12))\n# for i in range(64):\n#   plt.subplot(8,8, i+1)\n#   img = dataset[i] * std + mean # Denormalize the image: denormalized_image = (normalized_image * std) + mean\n#   plt.imshow(img.permute(1, 2, 0))\n#   plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2023-07-07T20:55:43.925971Z","iopub.execute_input":"2023-07-07T20:55:43.926372Z","iopub.status.idle":"2023-07-07T20:55:44.182860Z","shell.execute_reply.started":"2023-07-07T20:55:43.926340Z","shell.execute_reply":"2023-07-07T20:55:44.181272Z"},"trusted":true},"execution_count":25,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m64\u001b[39m):\n\u001b[1;32m      3\u001b[0m   plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m8\u001b[39m, i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m   img \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m \u001b[38;5;241m+\u001b[39m mean \u001b[38;5;66;03m# Denormalize the image: denormalized_image = (normalized_image * std) + mean\u001b[39;00m\n\u001b[1;32m      5\u001b[0m   plt\u001b[38;5;241m.\u001b[39mimshow(img\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m      6\u001b[0m   plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'float'"],"ename":"TypeError","evalue":"can't multiply sequence by non-int of type 'float'","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x1200 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"# DataLoader","metadata":{}},{"cell_type":"markdown","source":"# GAN Model","metadata":{}},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-07-07T19:24:40.231572Z","iopub.execute_input":"2023-07-07T19:24:40.231879Z","iopub.status.idle":"2023-07-07T19:24:40.244167Z","shell.execute_reply.started":"2023-07-07T19:24:40.231847Z","shell.execute_reply":"2023-07-07T19:24:40.243250Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"'cpu'"},"metadata":{}}]},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n\n        def block(in_channels, out_channels, kernel_size=4, stride=2, padding=1, normalize=True):\n            layers = [nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False)]\n            if normalize:\n                layers.append(nn.BatchNorm2d(out_channels))\n            layers.append(nn.LeakyReLU(0.2, inplace=True))\n            return layers\n\n        self.model = nn.Sequential(\n        # input is Z, going into a convolution\n        *block(latent_dim, 512, 4, 1, 0, normalize=False),  # First layer block\n            *block(512, 256, 4, 2, 1),  # 2nd layer block\n     *block(256, 128, 4, 2, 1), # 3rd layer block\n        *block(128, 64, 4, 2, 1),   # 4th layer block\n        *block(64, 32, 4, 2, 1),    # Added a fifth layer block\n        nn.ConvTranspose2d(32, channels, 3, 1, 1), # Final Convolutional layer\n        nn.Tanh() # Tanh activation for output       \n        )\n\n    def forward(self,z): # Forward propagation function\n#         print(\"z before exe in gen:\", z.shape)\n        z = z.view(z.size(0), z.size(1),1 ,1) # Reshape the input tensor in (B x C x H x W) format\n#         print(\"z shape in gen:\", z.shape)\n#         print(\"z inside gen:\", z)\n        img = self.model(z) # Pass input through the model\n        return img # Return the image\n","metadata":{"execution":{"iopub.status.busy":"2023-07-07T19:24:40.245718Z","iopub.execute_input":"2023-07-07T19:24:40.246096Z","iopub.status.idle":"2023-07-07T19:24:40.258763Z","shell.execute_reply.started":"2023-07-07T19:24:40.246063Z","shell.execute_reply":"2023-07-07T19:24:40.257831Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n\n        # Function to create a convolutional layer block (Conv -> LeakyReLU)\n        def block(in_channels, out_channels, kernel_size=4, stride=2, padding=1):\n            return [\n                nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n                nn.LeakyReLU(0.2, inplace=True)\n            ]\n\n        self.model = nn.Sequential(\n            *block(channels, 32),  # First layer block\n            *block(32, 64),  # Second layer block\n            *block(64, 128),  # Second layer block\n            *block(128, 256),  # Third layer block\n            *block(256, 512),  # Fourth layer block\n            nn.Conv2d(512, 1, 2, 1, 0),  # Final convolutional layer\n            nn.Sigmoid()  # Sigmoid activation for output\n        )\n\n    def forward(self, img):  # Forward propagation function\n        validity = self.model(img)  # Pass the image through the model\n#         validity = validity.view(validity.size(0), 1)  # Forcing the shape of the output\n        validity = validity.view(validity.size(0), -1)  # Flatten the output\n        return validity  # Return the validity","metadata":{"execution":{"iopub.status.busy":"2023-07-07T19:24:40.261482Z","iopub.execute_input":"2023-07-07T19:24:40.261835Z","iopub.status.idle":"2023-07-07T19:24:40.277544Z","shell.execute_reply.started":"2023-07-07T19:24:40.261806Z","shell.execute_reply":"2023-07-07T19:24:40.276476Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# # We use binary cross-entropy loss for the adversarial loss function\n# adversarial_loss = torch.nn.BCELoss()\n\n# # Initialize the generator and the discriminator\n# generator = Generator()\n# discriminator = Discriminator()\n\n# # If CUDA is available, we use it for the models and the loss function\n# if torch.cuda.is_available():\n#     generator.cuda()\n#     discriminator.cuda()\n#     adversarial_loss.cuda()\n\n\n# # We use the Adam optimizer for both the generator and the discriminator\n# optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n# optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n\n\n# # Initialize schedulers\n# scheduler_G = lr_scheduler.StepLR(optimizer_G, step_size=30, gamma=0.1)\n# scheduler_D = lr_scheduler.StepLR(optimizer_D, step_size=30, gamma=0.1)\n\n# #\n# Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor","metadata":{"execution":{"iopub.status.busy":"2023-07-07T19:24:40.278787Z","iopub.execute_input":"2023-07-07T19:24:40.279089Z","iopub.status.idle":"2023-07-07T19:24:40.353693Z","shell.execute_reply.started":"2023-07-07T19:24:40.279064Z","shell.execute_reply":"2023-07-07T19:24:40.352662Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# !mkdir 'training_predictions01'","metadata":{"execution":{"iopub.status.busy":"2023-07-07T19:24:40.354999Z","iopub.execute_input":"2023-07-07T19:24:40.355428Z","iopub.status.idle":"2023-07-07T19:24:41.384654Z","shell.execute_reply.started":"2023-07-07T19:24:40.355375Z","shell.execute_reply":"2023-07-07T19:24:41.383214Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory ‘training_predictions01’: File exists\n","output_type":"stream"}]},{"cell_type":"code","source":"# # Initialize list to store losses for Generator and Discriminator\n# g_losses = []\n# d_losses = []\n\n# # Training Loop\n# for epoch in tqdm(range(n_epochs)):  # Loop over the dataset multiple times, for each epoch\n#     g_loss_accum = 0.0\n#     d_loss_accum = 0.0\n#     num_batches = 0\n#     for i, (imgs) in enumerate(dataloader):  # Loop over each batch of real images in the dataset\n# #         print(imgs.shape)\n#         # Ground truths for real and fake images (real: 1, fake: 0)\n#         valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n#         fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n\n#         # Configure input, this will be used for training the discriminator with real images\n#         real_imgs = Variable(imgs.type(Tensor))\n\n#         # -----------------\n#         #  Train Generator\n#         # -----------------\n\n#         optimizer_G.zero_grad()  # Clears the gradients of all optimized tensors\n#         # Sample noise as generator input\n#         z = Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_dim)))\n# #         print(z.shape)\n        \n#         # zz = z.view(z.size(0), z.size(1), 1, 1) \n#         # print(zz.shape)\n\n#         # Generate a batch of images from the noise\n#         gen_imgs = generator(z)\n# #         print(gen_imgs.shape)\n# #         print(valid.shape)\n# #         print(discriminator(gen_imgs).shape)\n\n\n#         # Loss measures generator's ability to fool the discriminator\n#         g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n\n#         g_loss.backward()  # Compute the gradient of g_loss w.r.t. the Generator's parameters\n#         optimizer_G.step()  # Update the Generator's weights\n       \n\n#         # ---------------------\n#         #  Train Discriminator\n#         # ---------------------\n\n#         optimizer_D.zero_grad()  # Clears the gradients of all optimized tensors\n\n#         # Measure discriminator's ability to classify real from generated samples\n#         real_loss = adversarial_loss(discriminator(real_imgs), valid)  # Loss for real images\n#         fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)  # Loss for fake images\n#         d_loss = (real_loss + fake_loss) / 2  # Take the average of these two losses\n\n#         d_loss.backward()  # Compute the gradient of d_loss w.r.t. the Discriminator's parameters\n#         optimizer_D.step()  # Update the Discriminator's weights\n        \n\n#         # Accumulate losses for this batch\n#         g_loss_accum += g_loss.item()\n#         d_loss_accum += d_loss.item()\n#         num_batches += 1\n\n#     # Step the learning rate\n#     scheduler_G.step()\n#     scheduler_D.step()\n\n#     # Save average losses for this epoch\n#     g_losses.append(g_loss_accum / num_batches)\n#     d_losses.append(d_loss_accum / num_batches)\n    \n#         # Save a batch of generated images every 10 epochs\n#     if epoch % 10 == 0 or epoch == 100:\n#         save_image(gen_imgs.data[:25], f\"/kaggle/working/training_predictions01/epoch_{epoch}.png\", nrow=5, normalize=True)        ","metadata":{"execution":{"iopub.status.busy":"2023-07-07T19:24:41.387025Z","iopub.execute_input":"2023-07-07T19:24:41.387529Z","iopub.status.idle":"2023-07-07T19:25:36.616138Z","shell.execute_reply.started":"2023-07-07T19:24:41.387483Z","shell.execute_reply":"2023-07-07T19:25:36.614687Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/tmp/ipykernel_32/1229826153.py:12: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  im = iio.imread(f\"{self.im_fol}{self.im_list[idx]}\")\n  0%|          | 0/100 [00:55<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[60], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m     d_loss_accum \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m      9\u001b[0m     num_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (imgs) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):  \u001b[38;5;66;03m# Loop over each batch of real images in the dataset\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#         print(imgs.shape)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;66;03m# Ground truths for real and fake images (real: 1, fake: 0)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m         valid \u001b[38;5;241m=\u001b[39m Variable(Tensor(imgs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfill_(\u001b[38;5;241m1.0\u001b[39m), requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m         fake \u001b[38;5;241m=\u001b[39m Variable(Tensor(imgs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfill_(\u001b[38;5;241m0.0\u001b[39m), requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[0;32mIn[50], line 12\u001b[0m, in \u001b[0;36mMyDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m,idx):\n\u001b[0;32m---> 12\u001b[0m   im \u001b[38;5;241m=\u001b[39m \u001b[43miio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim_fol\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrans:\n\u001b[1;32m     14\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrans(im)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/imageio/__init__.py:97\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"imread(uri, format=None, **kwargs)\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03mReads an image from the specified file. Returns a numpy array, which\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m    to see what arguments are available for a particular format.\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting with ImageIO v3 the behavior of this function will switch to that of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m iio.v3.imread. To keep the current behavior (and make this warning disappear)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     95\u001b[0m )\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimread_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/imageio/v2.py:348\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m imopen_args \u001b[38;5;241m=\u001b[39m decypher_format_arg(\u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m    346\u001b[0m imopen_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mimopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mri\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mimopen_args\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m    349\u001b[0m     result \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/imageio/core/imopen.py:113\u001b[0m, in \u001b[0;36mimopen\u001b[0;34m(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m     request\u001b[38;5;241m.\u001b[39mformat_hint \u001b[38;5;241m=\u001b[39m format_hint\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[43mRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mio_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextension\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m source \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<bytes>\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(uri, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m uri\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# fast-path based on plugin\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# (except in legacy mode)\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/imageio/core/request.py:247\u001b[0m, in \u001b[0;36mRequest.__init__\u001b[0;34m(self, uri, mode, extension, format_hint, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Request.Mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# Parse what was given\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# Set extension\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extension \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/imageio/core/request.py:407\u001b[0m, in \u001b[0;36mRequest._parse_uri\u001b[0;34m(self, uri)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_read_request:\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# Reading: check that the file exists (but is allowed a dir)\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(fn):\n\u001b[0;32m--> 407\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m fn)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;66;03m# Writing: check that the directory to write to does exist\u001b[39;00m\n\u001b[1;32m    410\u001b[0m     dn \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(fn)\n","\u001b[0;31mFileNotFoundError\u001b[0m: No such file: '/kaggle/input/cub-200-2011/cub_200_2011_64x64_for_fid_10k/cub_200_2011_64x64_10k/965.png'"],"ename":"FileNotFoundError","evalue":"No such file: '/kaggle/input/cub-200-2011/cub_200_2011_64x64_for_fid_10k/cub_200_2011_64x64_10k/965.png'","output_type":"error"}]},{"cell_type":"code","source":"# # Plotting the losses\n# plt.figure(figsize=(10,5))\n# plt.title(\"Generator and Discriminator Loss During Training\")\n# plt.plot(g_losses,label=\"Generator\")\n# plt.plot(d_losses,label=\"Discriminator\")\n# plt.xlabel(\"epochs\")\n# plt.ylabel(\"Loss\")\n# plt.legend()\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-07T19:25:36.617165Z","iopub.status.idle":"2023-07-07T19:25:36.617582Z","shell.execute_reply.started":"2023-07-07T19:25:36.617384Z","shell.execute_reply":"2023-07-07T19:25:36.617415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}